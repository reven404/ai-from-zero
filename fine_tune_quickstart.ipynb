{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reven404/learning-ai-practice/blob/main/fine_tune_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c6730f-5d76-450b-9788-ec883d024f57",
      "metadata": {
        "id": "90c6730f-5d76-450b-9788-ec883d024f57"
      },
      "source": [
        "# Hugging Face Transformers 微调训练入门\n",
        "\n",
        "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
        "- 数据集下载\n",
        "- 数据预处理\n",
        "- 训练超参数配置\n",
        "- 训练评估指标设置\n",
        "- 训练器基本介绍\n",
        "- 实战训练\n",
        "- 模型保存"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe",
      "metadata": {
        "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe"
      },
      "source": [
        "## YelpReviewFull 数据集\n",
        "\n",
        "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
        "\n",
        "### 数据集摘要\n",
        "\n",
        "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
        "\n",
        "### 支持的任务和排行榜\n",
        "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
        "\n",
        "### 语言\n",
        "这些评论主要以英语编写。\n",
        "\n",
        "### 数据集结构\n",
        "\n",
        "#### 数据实例\n",
        "一个典型的数据点包括文本和相应的标签。\n",
        "\n",
        "来自YelpReviewFull测试集的示例如下：\n",
        "\n",
        "```json\n",
        "{\n",
        "    'label': 0,\n",
        "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
        "}\n",
        "```\n",
        "\n",
        "#### 数据字段\n",
        "\n",
        "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
        "- 'label': 对应于评论的分数（介于1和5之间）。\n",
        "\n",
        "#### 数据拆分\n",
        "\n",
        "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n",
        "\n",
        "## 下载数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PcHc-vng4hGW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcHc-vng4hGW",
        "outputId": "5d85b37f-e35b-44ce-eb90-62b0c40d9ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "WORK_HOME='/content/drive/MyDrive/Colab Notebooks'\n",
        "os.environ['TRANSFORMERS_CACHE'] = f'{WORK_HOME}/NLP/HuggingfaceCash'\n",
        "os.environ['HF_DATASETS_CACHE'] = f'{WORK_HOME}/NLP/HuggingfaceCash/Datasets'\n",
        "os.environ['HF_HOME'] = f'{WORK_HOME}/hf'\n",
        "os.environ['HF_HUB_CACHE'] = f'{WORK_HOME}/hf/hub/cache'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QtjC40zzSiwo",
      "metadata": {
        "id": "QtjC40zzSiwo"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "!pip install torch>=2.1.2 transformers timm datasets evaluate scikit-learn pandas peft accelerate autoawq optimum auto-gptq bitsandbytes>0.39.0 jiwer soundfile>=0.12.1 librosa langchain gradio trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
        "outputId": "eaaa3349-6a99-4649-ce73-820b940f9989"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"yelp_review_full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
        "outputId": "aa75648e-1bf5-4c0d-fb2a-e67b09b08e65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 650000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
        "outputId": "7c43d611-56ca-4d40-8782-f97405849470"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'label': 2,\n",
              " 'text': 'Having lived near this Atria\\'s location in the past, I can say that I\\'ve spent more than my fair share of time at the PNC Park Atria\\'s. My wife and I stopped in this past week, and for me, I was reminded of why I enjoy Atria\\'s...but this having been our first time at Atria\\'s together, and witnessing my wife\\'s experience, I realized why the place could garner such low reviews.\\\\n\\\\nFor someone like myself, who\\'s actually had enough positive and negative food experiences at Atria\\'s to know exactly what to order and what to steer clear of, I can make the experience a positive one, but that\\'s a situation I\\'m afforded now thanks to my previous patience and convenience. My wife, opting to stray from my suggestions had an awful dinner. Her plate of bland fish and asparagus left her turned off completely. Luckily, we were using a gift card, so it wasn\\'t as frustrating for her as it could\\'ve been. Regardless, walking away from an entire plate of food is disheartening.\\\\n\\\\nThat led me to realize this: If you\\'re only at Atria\\'s once, you\\'re odds aren\\'t that great of having a good experience. That\\'s just the reality of the situation. There are a handful of really good things on the menu that I LOVE. The parmesan crusted chicken is really good, although it can sometimes be a little too oily. The pot roast is excellent, but it\\'s way too heavy for most of the year...ESPECIALLY during baseball season when they\\'re busier. Their chili is really on-point...especially paired with their bread, and the salmon salad is excellent. Although, I don\\'t like the salmon, so I swap the salmon for chicken for a great salad option. The carrot cake is insanely good, but truth be told, it\\'s not homemade. I could care less, though, as it\\'s still some of the best carrot cake I\\'ve ever eaten. Period. Other notable items are the pot roast nachos, crab cakes, red skin smashed potatoes, and the reuben.\\\\n\\\\nThat\\'s really where the positives end, though. I\\'ve learned to steer clear of the burgers because of the inconsistency with which they\\'re prepared. I\\'ve received more undercooked burgers at Atria\\'s than any other restaurant, and it\\'s just not worth the gamble anymore. My filets have always been perfectly-prepared, but the one time I got a strip it was practically burned on one side and undercooked on the other. Failing to cook burgers and steaks correctly isn\\'t that surprising, but deciding to serve them to customers despite their incorrect preparation IS surprising...and poor.\\\\n\\\\nI know that the last time I had salmon on my salad, the fish tasted \\\\\"off\\\\\" and I paid the price for it later. I\\'ve never given a single fish meal a chance there since (we\\'re talking years now). Hence, my request for chicken on my salads now. Most of the meals that I\\'ve had are average, and I\\'ve practically tried the entirety of the menu over the years, so believe me when I say it.\\\\n\\\\nWhy do I continue to go? Well, because the few items that I do love, are crave-worthy, and having become a regular (less so, nowadays), the service that I received at the bar was always excellent. Daniel and Roy have always provided  great service to me, and good service goes the distance, as far I\\'m concerned, so it\\'s been worth stopping in from time-to-time. Unfortunately, if I can\\'t sit at the bar, I don\\'t always stick around, as the service at the tables is really hit-or-miss. For every good server they have, they have two more that could care less about their jobs...especially during peak times.\\\\n\\\\nRegardless, this is my favorite Atria\\'s location, because it\\'s the least \\\\\"stuffy\\\\\" and pretentious location of them all, but there\\'s still a lot of room to improve...and I hope it does.'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][1234]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d",
      "metadata": {
        "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622",
      "metadata": {
        "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622"
      },
      "outputs": [],
      "source": [
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset) - 1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset) - 1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af560b6-7d21-499e-9b82-114be371a98a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1af560b6-7d21-499e-9b82-114be371a98a",
        "outputId": "2665869e-b09f-40f9-e053-2466c3d0d417"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 stars</td>\n",
              "      <td>Always great food, drinks &amp; energy! If you are at the Fashion Show Mall this place is worth your visit. Good margaritas and yummy food! Their special events are excellent too. I have not had a chance to go to the cooking events but I have wanted to. It was fun to do Cinco de Mayo here!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 star</td>\n",
              "      <td>Like most reviewers have said, its overpriced.  The food is good, but not good enough to justify a $60 bill for one glass of wine and \\\"good\\\" crab cakes.  And there are no frills - no bread for the table, no sides, nada...so if I'm going to pay that much for a meal I better get more than 2 crab cakes and a glass of wine.  I was disappointed and I feel like I could spend less than that and get a fantastic meal at a place like Eleven.  \\n\\nAlso the service left much to be desired during our trip there.  Earlier that day, I had made reservations online but I had somehow messed up the online reservation, but called the restaurant immediately after realizing my mistake to let them know the glitch with the online reservation.  The gentleman I spoke with said he would take care of it and there would be no problem and my reservation would be changed to reflect the day/time we wanted. \\n\\nFast forward 6 hours and the hostess was completely clueless and said that we didn't have a reservation for us.  I explained the situation from earlier that day but I was met with 3 hostess people looking at each other and the computer screen of reservations with confusion.  They talked it over and said that they would get us a table shortly...now I'm not sure what \\\"shortly\\\" means to most people, but my expectation was 5-10 minutes.  Fast forward 25 minutes later, with no updates from them during this time, it was my friend and I who were pestering them with what was going on.  We would have been find if they told us that sorry but we are unable to accommodate you, rather than having us wait in their lobby area for nearly 30 minutes!\\n\\nAll in all - sub par experience and I doubt I'd go back.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 stars</td>\n",
              "      <td>Tried out a slider and wasn't very impressed. However, I will say that the tomato bisque is simply delectable and should definitely be tried. What I found odd was that the waiters have numbers as name tags instead of their actual names... Are these waiters nothing but numbers to this establishment? Haha, I hope not.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2 star</td>\n",
              "      <td>Horrible horrible went with a friend his 2nd time there he had bad experience the first time but went on the first day (no waffles or sweet potato pancakes) so we went around noon place has been open for 2 weeks nice hostess got a table right away then sat there for 10 mins befits someone took our drink order still missing waffles on the menu so I went for a burger I wanted soup the waitress said it's not ready it was 1245pm 1/2hr later we got our food ehhh jus a burger not impressed saw some of the Mack bros there on the way out as we paid hostess asked how it was and I said ok actually not good 1/2hr for 2 burgers that sucked and are over priced he over heard and stared me down like he was gonna fight me lol I'll never go back there again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4 stars</td>\n",
              "      <td>Sal\\u00fad is a welcome addition to the neighborhood, especially across from my favorite yoga studio. The staff was very helpful and blended my juice fresh for me, which I appreciated. I am looking forward to returning soon!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4 stars</td>\n",
              "      <td>La Santisima, known in a past life as La Condesa, makes some of the best...THE BEST burritos and salsas in the valley. It looks like fast casual food, but it's a sit down restaurant that costs less than competitors while offering way higher quality eats. \\n\\nLike the 15+ varieties of salsa, ranging from a spicy, smoky chipotle to a light, creamy cilantro. Your food is going to take forever, so you might as well enjoy as many as you can. They all come across as very fresh--none of that canned crap. \\n\\nMy burrito, the Gaucho, was up there with the best I've had. And I've had a LOT of burros. The grilled white cheese, rich steak that had a faint wine flavor, cucumbers, and some peppers. Amazing. Great! The portion was huge as well, and I could barely finish it. I have a HUGE appetite. \\n\\nThe coolest part was that it was only around $9. That's somewhere between fast-casual and sit-down prices, but with better quality than virtually any Mexican restaurant. For about another $4 you can add some awesome aguas frescas like the horchata, complete with a touch of strawberry. I actually don't like that type of fruit infusion in something I expect to be straight up rice and cinnamon, but I can appreciate the quality ingredients. \\n\\nI'm sold on this place, and I definitely recommend you should go, but that doesn't mean I'm going to overlook a few flaws that irk me. The first is that I'm not sure the furniture is either comfortable, tasteful, or clean. The high wooden tables are much obliged for taller patrons like myself, but they were sticky...despite being actively cleaned as we walked in. Gross. The seats are shoddy as well. The airbrush-on-canvas Frida Kahlo paired with the \\\"no no THIS IS HOW MEXICAN FOOD IS DONE WE USE PROPER NAMES\\\" motif on the menu give this a unique, yet eyeroll-worthy vibe I can best describe as try-hard and totally hipster. \\n\\nService is questionable as well. Although I appreciate that everyone who is not American actually takes their time at restaurants, I don't find anything particularly complex that warrants 20+ minutes for a burrito, and tacos/beans/rice for my dining partner. This is on top of the 10+ minutes it took to get a menu. We actually had to get up and grab them ourselves! They were not really paying attention. \\n\\nOh yeah, and then there's the warm tap water. Gross. \\n\\nAnyway, Santisima comes across as a place with great cooks that don't know how to run a restaurant. I can't say I enjoyed any aspect of dining in besides salsa sampling, and so I've gotta deduct points even though that was a 5-star burrito. Fortunately, you can avoid these issues by just ordering something to go, which is probably what I'll gladly do when I undoubtedly return.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5 stars</td>\n",
              "      <td>A long time ago in a toxic waste dump far away called New Jersey, a young boy had his first pizza, a thin crusted thin crust pizza with fresh toppings all over it. It was heaven to that boy and for the last 20 years he has been trying to find a western region version close to that perfect bite.  Those Guys Pies comes awfully close.  Led by Roy Bass, who helped start Secret Pizza at the Cosmo, Those Guys Pies not only makes superb pizza but excellent cheesesteak (Roy hails from Cherry Hill, just a skimming stone away from Philly), and even homemade mozzarella sticks.  The ingredients are fresh and clearly Roy and his partner in crime put east coast love into their creations.\\n\\nMy one regret is they do not serve slices at night.  Still, leftover pizza will be good in the morning :)\\n\\nEnjoy the pie with the transplanted east coaster Seal of Approval.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1 star</td>\n",
              "      <td>Bland food, rude service (from an Italian grandfather--which is weird); however,  I've since learned not to blame it on Peru!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1 star</td>\n",
              "      <td>I wish I'd consulted yelp. I came here this past week, after not eating for an entire day.\\n\\n I was super pissed my friend insisted on finishing his crappy $10ish meal, while I sat there sipping on sprite and trying to forget the horrifying food I'd just sampled.\\n\\n\\\"Do NOT go in there! Whoo!\\\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2 star</td>\n",
              "      <td>To put it bluntly there are better places to eat at for the money you would spend here. Landrys tries to be an upscale restaurant but really falls short. \\n\\nTo start I had the lobster bisque and it was good! I wish I had just stuck to the bisque as my crab cakes were disappointing. There was a bit too much breading and not enough crab. Additionally they put some weird sauce on the bottom of the plate which  I felt did not compliment the cakes.  My Freind had the clam chowder which she said was also ver good. \\n\\nThe atmosphere is slightly upscale- maybe more along the lines of \\\"I want to be an upscale restaurant but don't know how.\\\" Our server Rosa was very disinterested in us from the beginning when we told her water to start and let is look over the menu. She then proceeded to try and sell up some rewards card for $25.00- all of which happened before we really got to look at the menu and order..... Not the way you want to start off dinner!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62",
      "metadata": {
        "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62"
      },
      "source": [
        "## 预处理数据\n",
        "\n",
        "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
        "\n",
        "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
        "\n",
        "下面使用填充到最大长度的策略，处理整个数据集："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
        "outputId": "05c3fce4-4adf-4e72-9e5c-65a9f82d57b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
        "outputId": "5c7c9cad-dd48-4bad-a946-70d5cedcf678"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3 stars</td>\n",
              "      <td>I've come in here a few times and I must say that it is delicious food at cheap prices. I got an entire teriyaki bowl and dumplings with a drink for under 7 dollars. Decent atmosphere, it is usually quiet, so perhaps a good spot to get some work done as you eat. Great place for lunch w friends. Take out is always an option too. Check it out if you're in the mood for something asian and different.</td>\n",
              "      <td>[101, 146, 112, 1396, 1435, 1107, 1303, 170, 1374, 1551, 1105, 146, 1538, 1474, 1115, 1122, 1110, 13108, 2094, 1120, 10928, 7352, 119, 146, 1400, 1126, 2072, 21359, 16383, 2293, 7329, 1105, 17549, 11082, 1114, 170, 3668, 1111, 1223, 128, 5860, 119, 13063, 3452, 6814, 117, 1122, 1110, 1932, 3589, 117, 1177, 3229, 170, 1363, 3205, 1106, 1243, 1199, 1250, 1694, 1112, 1128, 3940, 119, 2038, 1282, 1111, 5953, 192, 2053, 119, 5055, 1149, 1110, 1579, 1126, 5146, 1315, 119, 23114, 1122, 1149, 1191, 1128, 112, 1231, 1107, 1103, 6601, 1111, 1380, 1112, 1811, 1105, 1472, 119, 102, 0, 0, ...]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b",
      "metadata": {
        "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b"
      },
      "source": [
        "### 数据抽样\n",
        "\n",
        "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
        "\n",
        "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17317d8-3c6a-467f-843d-87491f600db1",
      "metadata": {
        "id": "a17317d8-3c6a-467f-843d-87491f600db1"
      },
      "outputs": [],
      "source": [
        "full_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec",
      "metadata": {
        "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec"
      },
      "source": [
        "## 微调训练配置\n",
        "\n",
        "### 加载 BERT 模型\n",
        "\n",
        "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
        "outputId": "d36eb4eb-42fe-4f7f-ecb6-d430445f446f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44014df-b52c-4c72-9e9f-54424725a473",
      "metadata": {
        "id": "b44014df-b52c-4c72-9e9f-54424725a473"
      },
      "source": [
        "### 训练超参数（TrainingArguments）\n",
        "\n",
        "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
        "\n",
        "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
        "\n",
        "**最重要配置：模型权重保存路径(output_dir)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
        "outputId": "963f1d4d-b3b4-4171-f707-973d9761cfbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments,logging\n",
        "\n",
        "model_dir = f\"{WORK_HOME}/models/bert-base-cased-finetune-yelp\"\n",
        "\n",
        "logging.set_verbosity_info()\n",
        "\n",
        "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
        "training_args = TrainingArguments(output_dir=model_dir,\n",
        "                                  resume_from_checkpoint=True,\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  num_train_epochs=5,\n",
        "                                  logging_steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
        "outputId": "34dce2ee-db80-48ab-9dbf-4bcfcefe7579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/runs/Apr06_16-02-21_a4ab7d6551f4,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=100,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=True,\n",
            "run_name=/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 完整的超参数配置\n",
        "print(training_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebd3365-d359-4ab4-a300-4717590cc240",
      "metadata": {
        "id": "7ebd3365-d359-4ab4-a300-4717590cc240"
      },
      "source": [
        "### 训练过程中的指标评估（Evaluate)\n",
        "\n",
        "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
        "\n",
        "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。\n",
        "\n",
        "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f",
      "metadata": {
        "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254",
      "metadata": {
        "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254"
      },
      "source": [
        "\n",
        "接着，调用 `compute` 函数来计算预测的准确率。\n",
        "\n",
        "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19",
      "metadata": {
        "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1",
      "metadata": {
        "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1"
      },
      "source": [
        "#### 训练过程指标监控\n",
        "\n",
        "通常，为了监控训练过程中的评估指标变化，我们可以在`TrainingArguments`指定`evaluation_strategy`参数，以便在 epoch 结束时报告评估指标。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1",
        "outputId": "574f5a85-991b-4d61-a020-697d24603f91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=model_dir,\n",
        "                                  save_total_limit=2,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  # per_device_eval_batch_size=32,\n",
        "                                  num_train_epochs=3,\n",
        "                                  logging_steps=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12",
      "metadata": {
        "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12"
      },
      "source": [
        "## 开始训练\n",
        "\n",
        "### 实例化训练器（Trainer）\n",
        "\n",
        "`kernel version` 版本问题：暂不影响本示例代码运行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
        "outputId": "f20baf2d-40f4-4024-c169-5761707ccded"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    # train_dataset=small_train_dataset,\n",
        "    train_dataset=full_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157",
      "metadata": {
        "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157"
      },
      "source": [
        "## 使用 nvidia-smi 查看 GPU 使用\n",
        "\n",
        "为了实时查看GPU使用情况，可以使用 `watch` 指令实现轮询：`watch -n 1 nvidia-smi`:\n",
        "\n",
        "```shell\n",
        "Every 1.0s: nvidia-smi                                       a4ab7d6551f4: Sat Apr  6 16:07:06 2024\n",
        "\n",
        "Sat Apr  6 16:07:06 2024\n",
        "+---------------------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
        "|-----------------------------------------+----------------------+----------------------+\n",
        "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                                         |                      |               MIG M. |\n",
        "|=========================================+======================+======================|\n",
        "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   77C    P0              61W /  70W |  11843MiB / 15360MiB |    100%      Default |\n",
        "|                                         |                      |                  N/A |\n",
        "+-----------------------------------------+----------------------+----------------------+\n",
        "\n",
        "+---------------------------------------------------------------------------------------+\n",
        "| Processes:                                                                            |\n",
        "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
        "|        ID   ID                                                             Usage      |\n",
        "|=======================================================================================|\n",
        "+---------------------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accfe921-471d-481a-96da-c491cdebad0c",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "accfe921-471d-481a-96da-c491cdebad0c",
        "outputId": "35bd8288-249c-4b94-994d-9735fda97420"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading model from /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-116500.\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 650,000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 121,875\n",
            "  Number of trainable parameters = 108,314,117\n",
            "  Continuing training from checkpoint, will skip to saved global_step\n",
            "  Continuing training from epoch 2\n",
            "  Continuing training from global step 116500\n",
            "  Will skip the first 2 epochs then the first 35250 batches in the first epoch.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='121875' max='121875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [121875/121875 2:16:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.599300</td>\n",
              "      <td>0.727575</td>\n",
              "      <td>0.710000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-117000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-117000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-117000/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-116000] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-117500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-117500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-117500/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-116500] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-118000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-118000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-118000/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-117000] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-118500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-118500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-118500/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-117500] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-119000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-119000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-119000/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-118000] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-119500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-119500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-119500/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-118500] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-120000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-120000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-120000/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-119000] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-120500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-120500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-120500/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-119500] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-121000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-121000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-121000/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-120000] due to args.save_total_limit\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-121500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-121500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/tmp-checkpoint-121500/model.safetensors\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/checkpoint-120500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=121875, training_loss=0.0264668609775641, metrics={'train_runtime': 8164.7464, 'train_samples_per_second': 238.832, 'train_steps_per_second': 14.927, 'total_flos': 5.1345926792994816e+17, 'train_loss': 0.0264668609775641, 'epoch': 3.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# trainer.train()\n",
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d581099-37a4-4470-b051-1ada38554089",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6d581099-37a4-4470-b051-1ada38554089"
      },
      "outputs": [],
      "source": [
        "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
        "outputId": "1b5769c4-1461-4e9b-cddf-08362168a2bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.9230320453643799,\n",
              " 'eval_accuracy': 0.6,\n",
              " 'eval_runtime': 5.378,\n",
              " 'eval_samples_per_second': 18.594,\n",
              " 'eval_steps_per_second': 2.417,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(small_test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52",
      "metadata": {
        "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52"
      },
      "source": [
        "### 保存模型和训练状态\n",
        "\n",
        "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
        "- 使用 `trainer.save_state` 方法保存训练状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
        "outputId": "e05eb248-a5ed-4244-adfd-704edc837a5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/models/bert-base-cased-finetune-yelp/model.safetensors\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e30510-0536-49d4-8e1b-43fc25272bde",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f6e30510-0536-49d4-8e1b-43fc25272bde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "badf5868-2847-439d-a73e-42d1cca67b5e",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "badf5868-2847-439d-a73e-42d1cca67b5e"
      },
      "outputs": [],
      "source": [
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9441ad-f65a-42b7-9016-4809c78285e9",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8c9441ad-f65a-42b7-9016-4809c78285e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a"
      },
      "outputs": [],
      "source": [
        "# trainer.model.save_pretrained(\"./\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}