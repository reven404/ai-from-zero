{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9684ec5f-9460-4876-9883-69380eacb0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:42:55.938445Z",
     "start_time": "2024-03-23T15:42:27.735129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27ad1a1650b64fada2e89c6fd2b00743"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd69bb311eaf44cf81ef70311cbc4b68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b7a6b648979493ab06cc8504c904551"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc9bdf8d0fca43a0b1bf628b68c4c433"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c92a7ffa6101417e8895b393bd8ca01b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "712afb1f848a46aa85cd7ecd80fce962"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a891f20ce2954c2f8af09ed7051acdc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[{'label': 'neutral', 'score': 0.8286516666412354}]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from transformers import pipeline\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\", model='SamLowe/roberta-base-go_emotions' )\n",
    "pipe(\"今儿上海可真冷啊\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a12486-952a-447d-9e90-6b041349a26e",
   "metadata": {},
   "source": [
    "### 测试更多示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee67f529-3d32-4834-b29a-e51a65cf4d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:43:01.680007Z",
     "start_time": "2024-03-23T15:43:01.618795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'neutral', 'score': 0.9198037385940552}]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"我觉得这家店蒜泥白肉的味道一般\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e104034-94ca-4370-8d35-438501c29ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:43:04.738243Z",
     "start_time": "2024-03-23T15:43:04.686530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'neutral', 'score': 0.84428471326828}]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认使用的模型 distilbert-base-uncased-finetuned-sst-2-english \n",
    "# 并未针对中文做太多训练，中文的文本分类任务表现未必满意\n",
    "pipe(\"你学东西真的好快，理论课一讲就明白了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c3d11aa-d523-491c-8910-bdc8aba49487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:36:48.211059Z",
     "start_time": "2024-03-23T15:36:48.156885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'Negative', 'score': 0.6106209754943848}]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 替换为英文后，文本分类任务的表现立刻改善\n",
    "pipe(\"You learn things really quickly. You understand the theory class as soon as it is taught.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09df7300-2f0d-4bc4-9572-0631658e8253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:36:51.958962Z",
     "start_time": "2024-03-23T15:36:51.900501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'Negative', 'score': 0.7923162579536438}]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Today Shanghai is really cold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1390396e-1af8-497f-85d9-6c9e984b4609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:37:03.027601Z",
     "start_time": "2024-03-23T15:37:02.877110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'Negative', 'score': 0.7923162579536438},\n {'label': 'Negative', 'score': 0.751470148563385},\n {'label': 'Negative', 'score': 0.6106209754943848}]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"Today Shanghai is really cold.\",\n",
    "    \"I think the taste of the garlic mashed pork in this store is average.\",\n",
    "    \"You learn things really quickly. You understand the theory class as soon as it is taught.\"\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686758b-d7f7-4df9-889d-e63af47a138a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用 Pipeline API 调用更多预定义任务\n",
    "\n",
    "## Natural Language Processing(NLP)\n",
    "\n",
    "**NLP**(自然语言处理)任务是最常见的任务类型之一，因为文本是我们进行交流的一种自然方式。要将文本转换为模型可识别的格式，需要对其进行分词。这意味着将一系列文本划分为单独的单词或子词（标记），然后将这些标记转换为数字。结果就是，您可以将一系列文本表示为一系列数字，并且一旦您拥有了一系列数字，它就可以输入到模型中来解决各种NLP任务！\n",
    "\n",
    "上面演示的 文本分类任务，以及接下来的标记、问答等任务都属于 NLP 范畴。\n",
    "\n",
    "### Token Classification\n",
    "\n",
    "在任何NLP任务中，文本都经过预处理，将文本序列分成单个单词或子词。这些被称为tokens。\n",
    "\n",
    "**Token Classification**（Token分类）将每个token分配一个来自预定义类别集的标签。\n",
    "\n",
    "两种常见的 Token 分类是：\n",
    "\n",
    "- 命名实体识别（NER）：根据实体类别（如组织、人员、位置或日期）对token进行标记。NER在生物医学设置中特别受欢迎，可以标记基因、蛋白质和药物名称。\n",
    "- 词性标注（POS）：根据其词性（如名词、动词或形容词）对标记进行标记。POS对于帮助翻译系统了解两个相同的单词如何在语法上不同很有用（作为名词的银行与作为动词的银行）。\n",
    "\n",
    "模型主页：https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d5a27fe-87d0-45fc-a31a-9a8db23e290a"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f1ed125-f9ed-42d9-b102-dbc3172baefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:49:55.204685Z",
     "start_time": "2024-03-23T15:49:16.333728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abd4a0a270c448cb82978eb17b9bf384"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3081c9e441a464e887408aa800af1cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "335588c6966145149c5c51fa6fd5ab2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7758891f3bf746d88fc2d9548bccff30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80c32a0bafae4a6297fa0eeaf1668d12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67f43b4870e04deab865803098e15a75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "transformers.pipelines.token_classification.TokenClassificationPipeline"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\", model='dslim/bert-base-NER')\n",
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68bab77c-0fe6-4781-b978-02d56829db33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:50:58.716742Z",
     "start_time": "2024-03-23T15:50:58.622505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-ORG', 'score': 0.8935, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.915, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9777, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'B-MISC', 'score': 0.9996, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'B-LOC', 'score': 0.9995, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9994, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9996, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c72d55-e574-444f-96bc-62704022a148",
   "metadata": {},
   "source": [
    "#### 合并实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b441191-6156-44b8-a323-db461ad06efb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T15:54:01.234047Z",
     "start_time": "2024-03-23T15:53:03.863443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/5.14k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21d935d321c84c5cbca52c7f7542a521"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/736M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4680190bb301402fa627b6d1dbafaee9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a300bb4c61441da92c49edd645252bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23533b60bfa14c9abaf21b9975b5aa52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "371212737e0c4205ba1bc1929461ba33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0eb0df327954aec95e3861e4e0ca526"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cdabb92a5924b1faaba8b206c52d18a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'entity_group': 'MEDICATION',\n  'score': 0.06327089,\n  'word': 'Hugg',\n  'start': 0,\n  'end': 4},\n {'entity_group': 'DETAILED_DESCRIPTION',\n  'score': 0.103796676,\n  'word': 'ing',\n  'start': 4,\n  'end': 7},\n {'entity_group': 'BIOLOGICAL_STRUCTURE',\n  'score': 0.079104,\n  'word': 'Face',\n  'start': 7,\n  'end': 12}]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True ,model='Clinical-AI-Apollo/Medical-NER')\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369dda97-bd1a-4cb0-9636-47c2308c6289",
   "metadata": {},
   "source": [
    "### Question Answering\n",
    "\n",
    "**Question Answering**(问答)是另一个token-level的任务，返回一个问题的答案，有时带有上下文（开放领域），有时不带上下文（封闭领域）。每当我们向虚拟助手提出问题时，例如询问一家餐厅是否营业，就会发生这种情况。它还可以提供客户或技术支持，并帮助搜索引擎检索您要求的相关信息。\n",
    "\n",
    "有两种常见的问答类型：\n",
    "\n",
    "- 提取式：给定一个问题和一些上下文，模型必须从上下文中提取出一段文字作为答案\n",
    "- 生成式：给定一个问题和一些上下文，答案是根据上下文生成的；这种方法由`Text2TextGenerationPipeline`处理，而不是下面展示的`QuestionAnsweringPipeline`\n",
    "\n",
    "模型主页：https://huggingface.co/distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5281b0b-6b57-4884-92e1-cc2677987360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:23:37.530559Z",
     "start_time": "2024-03-23T16:22:53.235119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ba5eca7695b4d48834c3fc820f9322d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24681264b8da44af9632811c4a451b54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76cacbaf9bb84766bc50f0981895541d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90c19fdfe4c141e1a18ba67dd5325e82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4e0fbde670c4f0cafb675e852b9ba37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec572c22248d4e8880ba49ca2ee719c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "transformers.pipelines.question_answering.QuestionAnsweringPipeline"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(task=\"question-answering\", model='timpal0l/mdeberta-v3-base-squad2')\n",
    "type(question_answerer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca674a51-30a4-4dea-a443-e428925e990f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:24:02.623690Z",
     "start_time": "2024-03-23T16:24:02.509750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9839, start: 29, end: 54, answer:  huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2158feb-a528-410a-aabf-f3bd7f2726c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:24:05.259397Z",
     "start_time": "2024-03-23T16:24:05.170568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7734, start: 44, end: 89, answer:  南市食品街是一座回廊式三层建筑，在这里汇集了天津各种经典的小吃，是品尝天津美食的好地方。\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"天津最好吃的是?\",\n",
    "    context=\"天津特产：天津甘栗、天津冬菜、天津大白菜、独流老醋、狗不理包子、十八街麻花、耳朵眼炸糕。 南市食品街是一座回廊式三层建筑，在这里汇集了天津各种经典的小吃，是品尝天津美食的好地方。\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1d7e5-6baa-4142-81c1-5d311c0440e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd7483-99a5-4f2a-894c-13cf5a3b71b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d995cb85-ab8f-4b28-9413-1a83fa3e4c4d",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "\n",
    "**Summarization**(文本摘要）从较长的文本中创建一个较短的版本，同时尽可能保留原始文档的大部分含义。摘要是一个序列到序列的任务；它输出比输入更短的文本序列。有许多长篇文档可以进行摘要，以帮助读者快速了解主要要点。法案、法律和财务文件、专利和科学论文等文档可以摘要，以节省读者的时间并作为阅读辅助工具。\n",
    "\n",
    "与问答类似，摘要有两种类型：\n",
    "\n",
    "- 提取式：从原始文本中识别和提取最重要的句子\n",
    "- 生成式：从原始文本中生成目标摘要（可能包括输入文件中没有的新单词）；`SummarizationPipeline`使用生成式方法\n",
    "\n",
    "模型主页：https://huggingface.co/t5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e028f36-2b50-4ae3-8dce-2f0ac685e8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:26:35.152160Z",
     "start_time": "2024-03-23T16:25:29.292524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c4575ee575f4917bb6f4f7d67f119e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d288207054084af48b186a60101b5443"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c54b39d37be04eebb2ae5e0374fa6510"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c57d1b5bdedc42abaa2d32b006a7fc0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3baefcf10f2f4908ad2ab7133e5739f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a06eebc45b764e55857a16c48e1a101e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      # model=\"t5-base\",\n",
    "                      model=\"facebook/bart-large-cnn\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c760bbf-2ae4-4f84-bd5e-32c30ee6bd78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:26:39.983182Z",
     "start_time": "2024-03-23T16:26:36.916306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'summary_text': 'The Transformer is the first sequence transduction model based entirely on attention. It replaces the recurrent layers most commonly used in encoder-decoder'}]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b50ff52b-e61e-40cd-ab66-a591dc0c3b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:26:53.790560Z",
     "start_time": "2024-03-23T16:26:51.098988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'summary_text': 'Transformers are a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. Unlike earlier recurrent neural'}]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    '''\n",
    "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data. \n",
    "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. \n",
    "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
    "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. \n",
    "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
    "    Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel. \n",
    "    This allows the data scientists to use GPUs for training transformer-based LLMs, significantly reducing the training time.\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72315144-7fae-4848-af79-a70e428b2416",
   "metadata": {},
   "source": [
    "\n",
    "## Audio 音频处理任务\n",
    "\n",
    "音频和语音处理任务与其他模态略有不同，主要是因为音频作为输入是一个连续的信号。与文本不同，原始音频波形不能像句子可以被划分为单词那样被整齐地分割成离散的块。为了解决这个问题，通常在固定的时间间隔内对原始音频信号进行采样。如果在每个时间间隔内采样更多样本，采样率就会更高，音频更接近原始音频源。\n",
    "\n",
    "以前的方法是预处理音频以从中提取有用的特征。现在更常见的做法是直接将原始音频波形输入到特征编码器中，以提取音频表示。这样可以简化预处理步骤，并允许模型学习最重要的特征。\n",
    "\n",
    "### Audio classification\n",
    "\n",
    "**Audio classification**(音频分类)是一项将音频数据从预定义的类别集合中进行标记的任务。这是一个广泛的类别，具有许多具体的应用，其中一些包括：\n",
    "\n",
    "- 声学场景分类：使用场景标签（“办公室”、“海滩”、“体育场”）对音频进行标记。\n",
    "- 声学事件检测：使用声音事件标签（“汽车喇叭声”、“鲸鱼叫声”、“玻璃破碎声”）对音频进行标记。\n",
    "- 标记：对包含多种声音的音频进行标记（鸟鸣、会议中的说话人识别）。\n",
    "- 音乐分类：使用流派标签（“金属”、“嘻哈”、“乡村”）对音乐进行标记。\n",
    "\n",
    "模型主页：https://huggingface.co/superb/hubert-base-superb-er\n",
    "\n",
    "数据集主页：https://huggingface.co/datasets/superb#er\n",
    "\n",
    "```\n",
    "情感识别（ER）为每个话语预测一个情感类别。我们采用了最广泛使用的ER数据集IEMOCAP，并遵循传统的评估协议：我们删除不平衡的情感类别，只保留最后四个具有相似数量数据点的类别，并在标准分割的五折交叉验证上进行评估。评估指标是准确率（ACC）。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4c1e9-8a67-4c72-8dce-ab326e0bc3b6",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装\n",
    "\n",
    "建议在命令行安装必要的音频数据处理包: ffmpeg\n",
    "\n",
    "```shell\n",
    "$apt update & apt upgrade\n",
    "$apt install -y ffmpeg\n",
    "$pip install ffmpeg ffmpeg-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e1f8a8d-75eb-49ab-9353-6c9d1f384cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:33:27.008964Z",
     "start_time": "2024-03-23T16:33:10.915233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08129dd8fafe4f6f9a2cebd273b9dd06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1979ed96b2604fc0a5e278faf92e3eb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f37f6ca57ef49dbb31af3c63faad467"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/learning-ai/lib/python3.11/site-packages/transformers/audio_utils.py:198: UserWarning: At least one mel filter has all zero values. The value for `num_mel_filters` (128) may be set too high. Or, the value for `num_frequency_bins` (256) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "204a4159-d14d-4623-8340-93d15abcc549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:34:09.355409Z",
     "start_time": "2024-03-23T16:34:07.601760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.4208, 'label': 'Speech'},\n {'score': 0.1793, 'label': 'Rain on surface'},\n {'score': 0.1301, 'label': 'Rain'},\n {'score': 0.096, 'label': 'Raindrop'},\n {'score': 0.0578, 'label': 'Music'}]"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 Hugging Face Datasets 上的测试文件\n",
    "preds = classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2528bf81-8289-4bb9-bf2d-c0ce9f7e8b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:34:24.852011Z",
     "start_time": "2024-03-23T16:34:23.995853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.4036, 'label': 'Music'},\n {'score': 0.1556, 'label': 'Marimba, xylophone'},\n {'score': 0.1161, 'label': 'Mallet percussion'},\n {'score': 0.1139, 'label': 'Glockenspiel'},\n {'score': 0.0637, 'label': 'Jingle, tinkle'}]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用本地的音频文件做测试\n",
    "preds = classifier(\"data/audio/Sample_BeeMoved_96kHz24bit.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6826a83-f5a5-454e-ac16-1f215abef861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e073cd1f-ba16-40a7-a029-bbd5e2a53dee",
   "metadata": {},
   "source": [
    "### Automatic speech recognition（ASR）\n",
    "\n",
    "**Automatic speech recognition**（自动语音识别）将语音转录为文本。这是最常见的音频任务之一，部分原因是因为语音是人类交流的自然形式。如今，ASR系统嵌入在智能技术产品中，如扬声器、电话和汽车。我们可以要求虚拟助手播放音乐、设置提醒和告诉我们天气。\n",
    "\n",
    "但是，Transformer架构帮助解决的一个关键挑战是低资源语言。通过在大量语音数据上进行预训练，仅在一个低资源语言的一小时标记语音数据上进行微调，仍然可以产生与以前在100倍更多标记数据上训练的ASR系统相比高质量的结果。\n",
    "\n",
    "模型主页：https://huggingface.co/openai/whisper-small\n",
    "\n",
    "下面展示使用 `OpenAI Whisper Small` 模型实现 ASR 的 Pipeline API 示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68d14f8c-1571-4889-abd4-8fde09dc610a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:39:04.751923Z",
     "start_time": "2024-03-23T16:37:06.083975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "654be8131e37438a9e637f73611c934f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93d5c576f47441478f5e70f066465cc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/3.90k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bd2131405c740dc821178e00d17a98e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c635d0eea0354fc3b1bf93b173534452"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "769fc8424a044504970cb21214b03637"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d80946cbc154d1fb9d747e4572c0800"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "423df3388bb441f09e8fea061822ea24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f175ba2ad0b473e9130f26ba4543263"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b1aebef33784b99b6c8d7ffe47c0221"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8841944f097f4fdfb012060b8613156b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b447ba0f8b646fabdc7c78d7f4ca361"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "316ebe18-9c8e-4ded-96b7-751304aa9122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:39:40.409299Z",
     "start_time": "2024-03-23T16:39:21.175112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'text': \" I'm not rich, I'm not a witch I just work from 9 to 5 No need to worry, don't feel so sorry I love hearing my favorite tunes Jazz and a bossa nova Electronica When I feel that it's good enough\"}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = transcriber(\"data/audio/Sample_BeeMoved_96kHz24bit.flac\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d5e06-ac4a-4a56-be36-9e445751bda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228b1482-1e13-4557-8d37-5d56e961b5c5",
   "metadata": {},
   "source": [
    "## Computer Vision 计算机视觉\n",
    "\n",
    "**Computer Vision**（计算机视觉）任务中最早成功之一是使用卷积神经网络（CNN）识别邮政编码数字图像。图像由像素组成，每个像素都有一个数值。这使得将图像表示为像素值矩阵变得容易。每个像素值组合描述了图像的颜色。\n",
    "\n",
    "计算机视觉任务可以通过以下两种通用方式解决：\n",
    "\n",
    "- 使用卷积来学习图像的层次特征，从低级特征到高级抽象特征。\n",
    "- 将图像分成块，并使用Transformer逐步学习每个图像块如何相互关联以形成图像。与CNN偏好的自底向上方法不同，这种方法有点像从一个模糊的图像开始，然后逐渐将其聚焦清晰。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bf9f4-6413-409b-968e-f03ca0c88367",
   "metadata": {},
   "source": [
    "### Image Classificaiton\n",
    "\n",
    "**Image Classificaiton**(图像分类)将整个图像从预定义的类别集合中进行标记。像大多数分类任务一样，图像分类有许多实际用例，其中一些包括：\n",
    "\n",
    "- 医疗保健：标记医学图像以检测疾病或监测患者健康状况\n",
    "- 环境：标记卫星图像以监测森林砍伐、提供野外管理信息或检测野火\n",
    "- 农业：标记农作物图像以监测植物健康或用于土地使用监测的卫星图像\n",
    "- 生态学：标记动物或植物物种的图像以监测野生动物种群或跟踪濒危物种\n",
    "\n",
    "模型主页：https://huggingface.co/google/vit-base-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98ca9736-10b9-45b0-a3e3-925f153bab57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:49:52.809989Z",
     "start_time": "2024-03-23T16:46:37.003032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6dc169ed0949b7b948840966768392"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/4.37G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0938170cbdf441748b957aeeb4db9e7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/369 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32e0a6ccfc5d463999604532184d42ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"image-classification\", model='shadowlilac/aesthetic-shadow-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8a41647-e8db-4d29-9dac-06c3c145acaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:50:29.452913Z",
     "start_time": "2024-03-23T16:50:27.492441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9893, 'label': 'lq'}\n",
      "{'score': 0.0107, 'label': 'hq'}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\n",
    "    \"https://img1.baidu.com/it/u=2785167107,879157852&fm=253&fmt=auto&app=138&f=JPEG?w=801&h=500\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67592129-6430-4349-8016-7dde511ff69b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:50:35.889159Z",
     "start_time": "2024-03-23T16:50:34.947410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6616, 'label': 'hq'}\n",
      "{'score': 0.3384, 'label': 'lq'}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\n",
    "    \"data/image/w1200.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7e9b51a-d759-4398-9894-f10933dbed47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:50:43.394910Z",
     "start_time": "2024-03-23T16:50:42.328146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5274, 'label': 'hq'}\n",
      "{'score': 0.4726, 'label': 'lq'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = classifier(\n",
    "    \"data/image/panda.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f5fdb-2803-4f4f-9008-00dee9a6a557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8118a561-3dc9-4693-8c3b-3e29c37b4d71",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "\n",
    "与图像分类不同，目标检测在图像中识别多个对象以及这些对象在图像中的位置（由边界框定义）。目标检测的一些示例应用包括：\n",
    "\n",
    "- 自动驾驶车辆：检测日常交通对象，如其他车辆、行人和红绿灯\n",
    "- 遥感：灾害监测、城市规划和天气预报\n",
    "- 缺陷检测：检测建筑物中的裂缝或结构损坏，以及制造业产品缺陷\n",
    "\n",
    "模型主页：https://huggingface.co/facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7122f04-7add-4623-8f3f-ccc00247524b",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc4227-cbcc-4f18-bf26-66535e66afb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3401126-756b-4394-930c-c833c1f574b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:51:00.222806Z",
     "start_time": "2024-03-23T16:50:50.280482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2468ff3bf08d4671badbf39d3e396cef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/115M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fc32c34a993428cb2eecb9255e75451"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9773224c3bf74ca98d06773623f8f522"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/274 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9015479d1e624c9a8f230a64ed7eb925"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "detector = pipeline(task=\"object-detection\", model='microsoft/table-transformer-structure-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32dc65d4-3868-4d10-a433-9f50832e8e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:51:11.375972Z",
     "start_time": "2024-03-23T16:51:09.920490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.9902,\n  'label': 'table',\n  'box': {'xmin': 67, 'ymin': 55, 'xmax': 880, 'ymax': 592}}]"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](data/image/w1200.jpeg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "550759be-93ab-4988-81f0-c0cb8eccfda8"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40f66cd7-f2c8-4af3-b9ab-60012792ec1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T16:51:25.712276Z",
     "start_time": "2024-03-23T16:51:25.468970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.9893,\n  'label': 'table',\n  'box': {'xmin': 59, 'ymin': 48, 'xmax': 809, 'ymax': 414}}]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"data/image/w1200.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1d591246-662b-47e0-8531-f862b05ba1ad",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d1565e1d-20bf-4b19-86c1-dd3a8983a999",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "id": "e4993a9f-1032-46ab-97b1-a028d4bd5ebc",
   "metadata": {},
   "source": [
    "### Homework：替换以上示例中的模型，对比不同模型在相同任务上的性能表现\n",
    "\n",
    "在 Hugging Face Models 中找到适合你的模型：https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f51d2-863d-44f6-836f-9051351985ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
